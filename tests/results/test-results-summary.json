{
  "total_time": 199.23657178878784,
  "total_categories": 9,
  "passed_categories": 3,
  "failed_categories": 6,
  "success_rate": 33.33333333333333,
  "results": [
    {
      "category": "Smoke Tests",
      "success": true,
      "returncode": 0,
      "duration": 1.593458890914917,
      "stdout": "\u001b[1m============================= test session starts ==============================\u001b[0m\nplatform darwin -- Python 3.12.7, pytest-8.4.1, pluggy-1.6.0 -- /opt/homebrew/anaconda3/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.7', 'Platform': 'macOS-15.5-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'flask': '1.3.0', 'html': '4.1.1', 'xdist': '3.8.0', 'metadata': '3.1.1', 'cov': '6.2.1', 'asyncio': '1.0.0'}}\nrootdir: /Users/jestes/mcp-manager\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, flask-1.3.0, html-4.1.1, xdist-3.8.0, metadata-3.1.1, cov-6.2.1, asyncio-1.0.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\n\u001b[1mcollecting ... \u001b[0mcollected 4 items\n\ntests/test_basic_commands.py::TestSmokeTests::test_application_starts \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestSmokeTests::test_core_commands_available \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestSmokeTests::test_error_handling_works \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestSmokeTests::test_list_command_baseline \u001b[32mPASSED\u001b[0m\n\n- generated xml file: /Users/jestes/mcp-manager/tests/results/test-results-smoke-tests.xml -\n============================= slowest 10 durations =============================\n0.92s call     tests/test_basic_commands.py::TestSmokeTests::test_list_command_baseline\n0.16s call     tests/test_basic_commands.py::TestSmokeTests::test_core_commands_available\n0.16s call     tests/test_basic_commands.py::TestSmokeTests::test_error_handling_works\n0.16s call     tests/test_basic_commands.py::TestSmokeTests::test_application_starts\n\n(6 durations < 0.005s hidden.  Use -vv to show these durations.)\n\u001b[32m============================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 1.41s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "stderr": "",
      "command": "python -m pytest tests/test_basic_commands.py::TestSmokeTests -m smoke --verbose --tb=short --durations=10 --junitxml=tests/results/test-results-smoke-tests.xml --color=yes -s"
    },
    {
      "category": "Unit Tests",
      "success": true,
      "returncode": 0,
      "duration": 18.19867181777954,
      "stdout": "\u001b[1m============================= test session starts ==============================\u001b[0m\nplatform darwin -- Python 3.12.7, pytest-8.4.1, pluggy-1.6.0 -- /opt/homebrew/anaconda3/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.7', 'Platform': 'macOS-15.5-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'flask': '1.3.0', 'html': '4.1.1', 'xdist': '3.8.0', 'metadata': '3.1.1', 'cov': '6.2.1', 'asyncio': '1.0.0'}}\nrootdir: /Users/jestes/mcp-manager\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, flask-1.3.0, html-4.1.1, xdist-3.8.0, metadata-3.1.1, cov-6.2.1, asyncio-1.0.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\n\u001b[1mcollecting ... \u001b[0mcollected 25 items\n\ntests/test_basic_commands.py::TestBasicCommands::test_help_command \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestBasicCommands::test_version_command \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestBasicCommands::test_basic_info_commands[list] \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestBasicCommands::test_basic_info_commands[list --scope user] \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestBasicCommands::test_basic_info_commands[list --scope project] \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestBasicCommands::test_basic_info_commands[status] \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestBasicCommands::test_basic_info_commands[system-info] \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestBasicCommands::test_command_help_subcommands \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestBasicCommands::test_invalid_command_handling \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestBasicCommands::test_missing_arguments_handling \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestDiscoveryCommands::test_basic_discover \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestDiscoveryCommands::test_discover_with_query[filesystem] \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestDiscoveryCommands::test_discover_with_query[sqlite] \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestDiscoveryCommands::test_discover_with_query[test] \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestDiscoveryCommands::test_discover_with_type_filter[npm] \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestDiscoveryCommands::test_discover_with_type_filter[docker] \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestDiscoveryCommands::test_discover_with_type_filter[docker-desktop] \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestDiscoveryCommands::test_discover_with_limit[1] \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestDiscoveryCommands::test_discover_with_limit[5] \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestDiscoveryCommands::test_discover_with_limit[10] \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestDiscoveryCommands::test_discover_update_catalog \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestDiscoveryCommands::test_discover_combined_options \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestSystemInformation::test_system_info_command \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestSystemInformation::test_status_command \u001b[32mPASSED\u001b[0m\ntests/test_basic_commands.py::TestSystemInformation::test_monitor_status_command \u001b[32mPASSED\u001b[0m\n\n- generated xml file: /Users/jestes/mcp-manager/tests/results/test-results-unit-tests.xml -\n============================= slowest 10 durations =============================\n1.69s call     tests/test_basic_commands.py::TestSystemInformation::test_status_command\n1.69s call     tests/test_basic_commands.py::TestBasicCommands::test_basic_info_commands[status]\n1.69s call     tests/test_basic_commands.py::TestSystemInformation::test_system_info_command\n1.68s call     tests/test_basic_commands.py::TestBasicCommands::test_basic_info_commands[system-info]\n0.92s call     tests/test_basic_commands.py::TestBasicCommands::test_basic_info_commands[list --scope project]\n0.92s call     tests/test_basic_commands.py::TestBasicCommands::test_basic_info_commands[list]\n0.91s call     tests/test_basic_commands.py::TestBasicCommands::test_basic_info_commands[list --scope user]\n0.80s call     tests/test_basic_commands.py::TestBasicCommands::test_command_help_subcommands\n0.75s call     tests/test_basic_commands.py::TestDiscoveryCommands::test_discover_with_query[filesystem]\n0.74s call     tests/test_basic_commands.py::TestDiscoveryCommands::test_discover_with_query[sqlite]\n\u001b[32m============================= \u001b[32m\u001b[1m25 passed\u001b[0m\u001b[32m in 18.02s\u001b[0m\u001b[32m ==============================\u001b[0m\n",
      "stderr": "",
      "command": "python -m pytest tests/test_basic_commands.py::TestBasicCommands tests/test_basic_commands.py::TestDiscoveryCommands tests/test_basic_commands.py::TestSystemInformation -m unit --verbose --tb=short --durations=10 --junitxml=tests/results/test-results-unit-tests.xml --color=yes -s"
    },
    {
      "category": "Server Management",
      "success": false,
      "returncode": 1,
      "duration": 37.6676709651947,
      "stdout": "\u001b[1m============================= test session starts ==============================\u001b[0m\nplatform darwin -- Python 3.12.7, pytest-8.4.1, pluggy-1.6.0 -- /opt/homebrew/anaconda3/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.7', 'Platform': 'macOS-15.5-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'flask': '1.3.0', 'html': '4.1.1', 'xdist': '3.8.0', 'metadata': '3.1.1', 'cov': '6.2.1', 'asyncio': '1.0.0'}}\nrootdir: /Users/jestes/mcp-manager\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, flask-1.3.0, html-4.1.1, xdist-3.8.0, metadata-3.1.1, cov-6.2.1, asyncio-1.0.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\n\u001b[1mcollecting ... \u001b[0mcollected 26 items\n\ntests/test_server_management.py::TestServerAddition::test_add_server_by_type[npm-npx @test/server-args0] \u001b[31mFAILED\u001b[0m\ntests/test_server_management.py::TestServerAddition::test_add_server_by_type[docker-docker run test/server-args1] \u001b[31mFAILED\u001b[0m\ntests/test_server_management.py::TestServerAddition::test_add_server_by_type[custom-python test_server.py-args2] \u001b[31mFAILED\u001b[0m\ntests/test_server_management.py::TestServerAddition::test_add_server_minimal_args \u001b[32mPASSED\u001b[0m\ntests/test_server_management.py::TestServerAddition::test_add_server_duplicate_name \u001b[31mFAILED\u001b[0m\ntests/test_server_management.py::TestServerAddition::test_add_server_invalid_type \u001b[32mPASSED\u001b[0m\ntests/test_server_management.py::TestServerAddition::test_add_server_missing_command \u001b[31mFAILED\u001b[0m\ntests/test_server_management.py::TestServerRemoval::test_remove_existing_server \u001b[31mFAILED\u001b[0m\ntests/test_server_management.py::TestServerRemoval::test_remove_nonexistent_server \u001b[31mFAILED\u001b[0m\ntests/test_server_management.py::TestServerRemoval::test_remove_with_confirmation \u001b[32mPASSED\u001b[0m\ntests/test_server_management.py::TestServerListing::test_list_empty_servers \u001b[32mPASSED\u001b[0m\ntests/test_server_management.py::TestServerListing::test_list_with_servers \u001b[32mPASSED\u001b[0m\ntests/test_server_management.py::TestServerListing::test_list_with_scope[user] \u001b[32mPASSED\u001b[0m\ntests/test_server_management.py::TestServerListing::test_list_with_scope[project] \u001b[32mPASSED\u001b[0m\ntests/test_server_management.py::TestServerListing::test_list_with_scope[global] \u001b[31mFAILED\u001b[0m\ntests/test_server_management.py::TestServerListing::test_list_with_filters \u001b[32mPASSED\u001b[0m\ntests/test_server_management.py::TestServerEnableDisable::test_enable_server \u001b[32mPASSED\u001b[0m\ntests/test_server_management.py::TestServerEnableDisable::test_disable_server \u001b[32mPASSED\u001b[0m\ntests/test_server_management.py::TestServerEnableDisable::test_enable_disable_nonexistent \u001b[31mFAILED\u001b[0m\ntests/test_server_management.py::TestPackageInstallation::test_install_package_basic \u001b[32mPASSED\u001b[0m\ntests/test_server_management.py::TestPackageInstallation::test_install_nonexistent_package \u001b[31mFAILED\u001b[0m\ntests/test_server_management.py::TestServerValidation::test_add_server_empty_name \u001b[31mFAILED\u001b[0m\ntests/test_server_management.py::TestServerValidation::test_add_server_empty_command \u001b[31mFAILED\u001b[0m\ntests/test_server_management.py::TestServerValidation::test_add_server_invalid_characters \u001b[31mFAILED\u001b[0m\ntests/test_server_management.py::TestServerLifecycle::test_complete_server_lifecycle \u001b[31mFAILED\u001b[0m\ntests/test_server_management.py::TestServerLifecycle::test_bulk_server_operations \u001b[32mPASSED\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m____ TestServerAddition.test_add_server_by_type[npm-npx @test/server-args0] ____\u001b[0m\n\u001b[1m\u001b[31mtests/test_server_management.py\u001b[0m:34: in test_add_server_by_type\n    \u001b[0mTestAssertions.assert_command_success(result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mAdd \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mserver_type\u001b[33m}\u001b[39;49;00m\u001b[33m server\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Add npm server\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main add test-npm-server --type npm --command npx @test/server --args --directory /tmp\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m_ TestServerAddition.test_add_server_by_type[docker-docker run test/server-args1] _\u001b[0m\n\u001b[1m\u001b[31mtests/test_server_management.py\u001b[0m:43: in test_add_server_by_type\n    \u001b[0mTestAssertions.assert_contains_all(\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:290: in assert_contains_all\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Added docker server appears in list\u001b[0m\n\u001b[1m\u001b[31mE   Missing items: ['test-docker-server']\u001b[0m\n\u001b[1m\u001b[31mE   In text: \u001b[0m\n\u001b[1m\u001b[31mE                                MCP Servers (4 total)                              \u001b[0m\n\u001b[1m\u001b[31mE   \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\u001b[0m\n\u001b[1m\u001b[31mE   \u2503 Name            \u2503 Type    \u2503 Sc\u2026 \u2503 Sta\u2026 \u2503 Command                             \u2503\u001b[0m\n\u001b[1m\u001b[31mE   \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\n\u001b[31m\u001b[1m_ TestServerAddition.test_add_server_by_type[custom-python test_server.py-args2] _\u001b[0m\n\u001b[1m\u001b[31mtests/test_server_management.py\u001b[0m:34: in test_add_server_by_type\n    \u001b[0mTestAssertions.assert_command_success(result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mAdd \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mserver_type\u001b[33m}\u001b[39;49;00m\u001b[33m server\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Add custom server\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main add test-custom-server --type custom --command python test_server.py --args --config test.json\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m______________ TestServerAddition.test_add_server_duplicate_name _______________\u001b[0m\n\u001b[1m\u001b[31mtests/test_server_management.py\u001b[0m:79: in test_add_server_duplicate_name\n    \u001b[0mTestAssertions.assert_command_failure(result2, \u001b[33m\"\u001b[39;49;00m\u001b[33mDuplicate server add\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:248: in assert_command_failure\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Duplicate server add\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main add test-duplicate-server --type custom --command echo duplicate\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Failure\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Success (returncode 0)\u001b[0m\n\u001b[1m\u001b[31mE   Output: \u274c Failed to add server: Failed to add server test-duplicate-server: Failed to \u001b[0m\n\u001b[1m\u001b[31mE   add server: Failed to add server: MCP server test-duplicate-server already \u001b[0m\n\u001b[1m\u001b[31mE   exists in user config\u001b[0m\n\u001b[31m\u001b[1m______________ TestServerAddition.test_add_server_missing_command ______________\u001b[0m\n\u001b[1m\u001b[31mtests/test_server_management.py\u001b[0m:102: in test_add_server_missing_command\n    \u001b[0mTestAssertions.assert_command_failure(result, \u001b[33m\"\u001b[39;49;00m\u001b[33mMissing command\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:248: in assert_command_failure\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Missing command\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main add test-no-command --type custom\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Failure\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Success (returncode 0)\u001b[0m\n\u001b[1m\u001b[31mE   Output: \u274c Failed to add server: Failed to add server test-no-command: 1 validation \u001b[0m\n\u001b[1m\u001b[31mE   error for Server\u001b[0m\n\u001b[1m\u001b[31mE   command\u001b[0m\n\u001b[1m\u001b[31mE     Value error, Server command cannot be empty \u001b[0m\n\u001b[1m\u001b[31mE       For further information visit https://errors.pyd\u001b[0m\n\u001b[31m\u001b[1m________________ TestServerRemoval.test_remove_existing_server _________________\u001b[0m\n\u001b[1m\u001b[31mtests/test_server_management.py\u001b[0m:121: in test_remove_existing_server\n    \u001b[0m\u001b[94massert\u001b[39;49;00m OutputValidator.validate_success_message(remove_result[\u001b[33m'\u001b[39;49;00m\u001b[33mstdout\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], \u001b[33m\"\u001b[39;49;00m\u001b[33mremove\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   assert False\u001b[0m\n\u001b[1m\u001b[31mE    +  where False = <function OutputValidator.validate_success_message at 0x10338d3a0>(\"Remove server 'test-remove-server'? [y/n]: Failed to remove server: EOF when reading a line\\n\", 'remove')\u001b[0m\n\u001b[1m\u001b[31mE    +    where <function OutputValidator.validate_success_message at 0x10338d3a0> = OutputValidator.validate_success_message\u001b[0m\n\u001b[31m\u001b[1m_______________ TestServerRemoval.test_remove_nonexistent_server _______________\u001b[0m\n\u001b[1m\u001b[31mtests/test_server_management.py\u001b[0m:140: in test_remove_nonexistent_server\n    \u001b[0m\u001b[94massert\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mnot found\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m result[\u001b[33m'\u001b[39;49;00m\u001b[33mstdout\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].lower() \u001b[95mor\u001b[39;49;00m \\\n\u001b[1m\u001b[31mE   assert ('not found' in \"remove server 'nonexistent-server-xyz'? [y/n]: failed to remove server: eof when reading a line\\n\" or 'does not exist' in \"remove server 'nonexistent-server-xyz'? [y/n]: failed to remove server: eof when reading a line\\n\")\u001b[0m\n\u001b[1m\u001b[31mE    +  where \"remove server 'nonexistent-server-xyz'? [y/n]: failed to remove server: eof when reading a line\\n\" = <built-in method lower of str object at 0x1036991a0>()\u001b[0m\n\u001b[1m\u001b[31mE    +    where <built-in method lower of str object at 0x1036991a0> = \"Remove server 'nonexistent-server-xyz'? [y/n]: Failed to remove server: EOF when reading a line\\n\".lower\u001b[0m\n\u001b[1m\u001b[31mE    +  and   \"remove server 'nonexistent-server-xyz'? [y/n]: failed to remove server: eof when reading a line\\n\" = <built-in method lower of str object at 0x1036991a0>()\u001b[0m\n\u001b[1m\u001b[31mE    +    where <built-in method lower of str object at 0x1036991a0> = \"Remove server 'nonexistent-server-xyz'? [y/n]: Failed to remove server: EOF when reading a line\\n\".lower\u001b[0m\n\u001b[31m\u001b[1m________________ TestServerListing.test_list_with_scope[global] ________________\u001b[0m\n\u001b[1m\u001b[31mtests/test_server_management.py\u001b[0m:198: in test_list_with_scope\n    \u001b[0mTestAssertions.assert_command_success(result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mList with scope \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mscope\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: List with scope global\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main list --scope global\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m___________ TestServerEnableDisable.test_enable_disable_nonexistent ____________\u001b[0m\n\u001b[1m\u001b[31mtests/test_server_management.py\u001b[0m:264: in test_enable_disable_nonexistent\n    \u001b[0m\u001b[94massert\u001b[39;49;00m OutputValidator.validate_error_message(result2[\u001b[33m'\u001b[39;49;00m\u001b[33mstderr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], \u001b[33m\"\u001b[39;49;00m\u001b[33mnot found\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   assert False\u001b[0m\n\u001b[1m\u001b[31mE    +  where False = <function OutputValidator.validate_error_message at 0x10338d440>(\"<frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredictable behaviour\\n[07/24/25 17:32:12] ERROR    Failed to remove server 'nonexistent-server': No   \\n                             user-scoped MCP server found with name:            \\n                             nonexistent-server                                 \\n                    ERROR    Failed to remove server 'nonexistent-server':      \\n                             Failed to remove server: No user-scoped MCP server \\n                             found with name: nonexistent-server                \\n                    ERROR    Error disabling server nonexistent-server: Failed  \\n                             to remove server: Failed to remove server: No      \\n                             user-scoped MCP server found with name:            \\n                             nonexistent-server                                 \\n\", 'not found')\u001b[0m\n\u001b[1m\u001b[31mE    +    where <function OutputValidator.validate_error_message at 0x10338d440> = OutputValidator.validate_error_message\u001b[0m\n\u001b[31m\u001b[1m___________ TestPackageInstallation.test_install_nonexistent_package ___________\u001b[0m\n\u001b[1m\u001b[31mtests/test_server_management.py\u001b[0m:292: in test_install_nonexistent_package\n    \u001b[0mTestAssertions.assert_command_failure(result, \u001b[33m\"\u001b[39;49;00m\u001b[33mInstall nonexistent package\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:248: in assert_command_failure\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Install nonexistent package\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main install-package nonexistent-package-xyz\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Failure\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Success (returncode 0)\u001b[0m\n\u001b[1m\u001b[31mE   Output: \ud83d\udd0d Searching for server with ID: nonexistent-package-xyz\u001b[0m\n\u001b[1m\u001b[31mE   \u274c Server with install ID 'nonexistent-package-xyz' not found\u001b[0m\n\u001b[1m\u001b[31mE   \ud83d\udca1 Try running 'mcp-manager discover' to see available servers\u001b[0m\n\u001b[31m\u001b[1m_______________ TestServerValidation.test_add_server_empty_name ________________\u001b[0m\n\u001b[1m\u001b[31mtests/test_server_management.py\u001b[0m:306: in test_add_server_empty_name\n    \u001b[0mTestAssertions.assert_command_failure(result, \u001b[33m\"\u001b[39;49;00m\u001b[33mEmpty server name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:248: in assert_command_failure\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Empty server name\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main add  --type custom --command test\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Failure\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Success (returncode 0)\u001b[0m\n\u001b[1m\u001b[31mE   Output: \u274c Failed to add server: Failed to add server : 1 validation error for Server\u001b[0m\n\u001b[1m\u001b[31mE   name\u001b[0m\n\u001b[1m\u001b[31mE     Value error, Server name cannot be empty \u001b[0m\n\u001b[1m\u001b[31mE       For further information visit https://errors.pydantic.dev/2.11/v/value\u001b[0m\n\u001b[31m\u001b[1m______________ TestServerValidation.test_add_server_empty_command ______________\u001b[0m\n\u001b[1m\u001b[31mtests/test_server_management.py\u001b[0m:315: in test_add_server_empty_command\n    \u001b[0mTestAssertions.assert_command_failure(result, \u001b[33m\"\u001b[39;49;00m\u001b[33mEmpty server command\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:248: in assert_command_failure\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Empty server command\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main add test-empty-cmd --type custom --command \u001b[0m\n\u001b[1m\u001b[31mE   Expected: Failure\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Success (returncode 0)\u001b[0m\n\u001b[1m\u001b[31mE   Output: \u274c Failed to add server: Failed to add server test-empty-cmd: 1 validation error\u001b[0m\n\u001b[1m\u001b[31mE   for Server\u001b[0m\n\u001b[1m\u001b[31mE   command\u001b[0m\n\u001b[1m\u001b[31mE     Value error, Server command cannot be empty \u001b[0m\n\u001b[1m\u001b[31mE       For further information visit https://errors.pydan\u001b[0m\n\u001b[31m\u001b[1m___________ TestServerValidation.test_add_server_invalid_characters ____________\u001b[0m\n\u001b[1m\u001b[31mtests/test_server_management.py\u001b[0m:334: in test_add_server_invalid_characters\n    \u001b[0mTestAssertions.assert_command_failure(result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mInvalid name: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00minvalid_name\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:248: in assert_command_failure\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Invalid name: test server\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main add test server --type custom --command test\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Failure\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Success (returncode 0)\u001b[0m\n\u001b[1m\u001b[31mE   Output: \u274c Failed to add server: Failed to add server test server\u001b[0m\n\u001b[31m\u001b[1m______________ TestServerLifecycle.test_complete_server_lifecycle ______________\u001b[0m\n\u001b[1m\u001b[31mtests/test_server_management.py\u001b[0m:354: in test_complete_server_lifecycle\n    \u001b[0mTestAssertions.assert_contains_all(\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:290: in assert_contains_all\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Lifecycle: Server in list\u001b[0m\n\u001b[1m\u001b[31mE   Missing items: ['test-lifecycle-server']\u001b[0m\n\u001b[1m\u001b[31mE   In text: \u001b[0m\n\u001b[1m\u001b[31mE                                MCP Servers (14 total)                             \u001b[0m\n\u001b[1m\u001b[31mE   \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\u001b[0m\n\u001b[1m\u001b[31mE   \u2503 Name            \u2503 Type    \u2503 Sc\u2026 \u2503 Sta\u2026 \u2503 Command                             \u2503\u001b[0m\n\u001b[1m\u001b[31mE   \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\n- generated xml file: /Users/jestes/mcp-manager/tests/results/test-results-server-management.xml -\n============================= slowest 10 durations =============================\n8.20s call     tests/test_server_management.py::TestServerLifecycle::test_bulk_server_operations\n3.67s call     tests/test_server_management.py::TestServerListing::test_list_with_servers\n3.22s call     tests/test_server_management.py::TestServerListing::test_list_with_filters\n1.87s call     tests/test_server_management.py::TestServerLifecycle::test_complete_server_lifecycle\n1.86s call     tests/test_server_management.py::TestServerEnableDisable::test_enable_disable_nonexistent\n1.86s call     tests/test_server_management.py::TestServerEnableDisable::test_enable_server\n1.83s call     tests/test_server_management.py::TestServerAddition::test_add_server_by_type[docker-docker run test/server-args1]\n1.82s call     tests/test_server_management.py::TestServerEnableDisable::test_disable_server\n1.82s call     tests/test_server_management.py::TestServerRemoval::test_remove_with_confirmation\n1.80s call     tests/test_server_management.py::TestServerAddition::test_add_server_duplicate_name\n\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n\u001b[31mFAILED\u001b[0m tests/test_server_management.py::\u001b[1mTestServerAddition::test_add_server_by_type[npm-npx @test/server-args0]\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_server_management.py::\u001b[1mTestServerAddition::test_add_server_by_type[docker-docker run test/server-args1]\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_server_management.py::\u001b[1mTestServerAddition::test_add_server_by_type[custom-python test_server.py-args2]\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_server_management.py::\u001b[1mTestServerAddition::test_add_server_duplicate_name\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_server_management.py::\u001b[1mTestServerAddition::test_add_server_missing_command\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_server_management.py::\u001b[1mTestServerRemoval::test_remove_existing_server\u001b[0m - assert False\n\u001b[31mFAILED\u001b[0m tests/test_server_management.py::\u001b[1mTestServerRemoval::test_remove_nonexistent_server\u001b[0m - assert ('not found' in \"remove server 'nonexistent-server-xyz'? [y/n]: fail...\n\u001b[31mFAILED\u001b[0m tests/test_server_management.py::\u001b[1mTestServerListing::test_list_with_scope[global]\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_server_management.py::\u001b[1mTestServerEnableDisable::test_enable_disable_nonexistent\u001b[0m - assert False\n\u001b[31mFAILED\u001b[0m tests/test_server_management.py::\u001b[1mTestPackageInstallation::test_install_nonexistent_package\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_server_management.py::\u001b[1mTestServerValidation::test_add_server_empty_name\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_server_management.py::\u001b[1mTestServerValidation::test_add_server_empty_command\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_server_management.py::\u001b[1mTestServerValidation::test_add_server_invalid_characters\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_server_management.py::\u001b[1mTestServerLifecycle::test_complete_server_lifecycle\u001b[0m - AssertionError: \n\u001b[31m======================== \u001b[31m\u001b[1m14 failed\u001b[0m, \u001b[32m12 passed\u001b[0m\u001b[31m in 37.49s\u001b[0m\u001b[31m ========================\u001b[0m\n",
      "stderr": "",
      "command": "python -m pytest tests/test_server_management.py --verbose --tb=short --durations=10 --junitxml=tests/results/test-results-server-management.xml --color=yes -s"
    },
    {
      "category": "Suite Management",
      "success": false,
      "returncode": 1,
      "duration": 19.223860025405884,
      "stdout": "\u001b[1m============================= test session starts ==============================\u001b[0m\nplatform darwin -- Python 3.12.7, pytest-8.4.1, pluggy-1.6.0 -- /opt/homebrew/anaconda3/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.7', 'Platform': 'macOS-15.5-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'flask': '1.3.0', 'html': '4.1.1', 'xdist': '3.8.0', 'metadata': '3.1.1', 'cov': '6.2.1', 'asyncio': '1.0.0'}}\nrootdir: /Users/jestes/mcp-manager\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, flask-1.3.0, html-4.1.1, xdist-3.8.0, metadata-3.1.1, cov-6.2.1, asyncio-1.0.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\n\u001b[1mcollecting ... \u001b[0mcollected 33 items\n\ntests/test_suite_management.py::TestSuiteCreation::test_create_basic_suite \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteCreation::test_create_suite_with_category \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteCreation::test_create_suites_different_categories[development] \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteCreation::test_create_suites_different_categories[production] \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteCreation::test_create_suites_different_categories[testing] \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteCreation::test_create_suites_different_categories[monitoring] \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteCreation::test_create_duplicate_suite \u001b[31mFAILED\u001b[0m\ntests/test_suite_management.py::TestSuiteCreation::test_create_suite_invalid_name \u001b[31mFAILED\u001b[0m\ntests/test_suite_management.py::TestSuiteServerManagement::test_add_server_to_suite \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteServerManagement::test_add_multiple_servers_to_suite \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteServerManagement::test_remove_server_from_suite \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteServerManagement::test_add_server_to_nonexistent_suite \u001b[31mFAILED\u001b[0m\ntests/test_suite_management.py::TestSuiteServerManagement::test_remove_server_from_nonexistent_suite \u001b[31mFAILED\u001b[0m\ntests/test_suite_management.py::TestSuiteListing::test_list_empty_suites \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteListing::test_list_multiple_suites \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteListing::test_list_suites_by_category[development] \u001b[31mFAILED\u001b[0m\ntests/test_suite_management.py::TestSuiteListing::test_list_suites_by_category[production] \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteListing::test_list_suites_by_category[testing] \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteListing::test_suite_summary \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteDetails::test_show_suite_details \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteDetails::test_show_nonexistent_suite \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteDetails::test_show_empty_suite \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteInstallation::test_suite_installation_dry_run \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteInstallation::test_suite_installation_actual \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteInstallation::test_suite_installation_nonexistent_suite \u001b[31mFAILED\u001b[0m\ntests/test_suite_management.py::TestSuiteInstallation::test_suite_installation_empty_suite \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteInstallation::test_suite_installation_options[--force] \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteInstallation::test_suite_installation_options[--skip-existing] \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteInstallation::test_suite_installation_options[--update-existing] \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteDeletion::test_delete_suite \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteDeletion::test_delete_suite_with_force \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteDeletion::test_delete_nonexistent_suite \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteWorkflows::test_complete_suite_lifecycle \u001b[32mPASSED\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m________________ TestSuiteCreation.test_create_duplicate_suite _________________\u001b[0m\n\u001b[1m\u001b[31mtests/test_suite_management.py\u001b[0m:85: in test_create_duplicate_suite\n    \u001b[0mTestAssertions.assert_command_failure(result2, \u001b[33m\"\u001b[39;49;00m\u001b[33mDuplicate suite creation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:248: in assert_command_failure\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Duplicate suite creation\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main suite create test-duplicate-suite --description Duplicate suite\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Failure\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Success (returncode 0)\u001b[0m\n\u001b[1m\u001b[31mE   Output: Creating suite 'test-duplicate-suite' with ID 'test-duplicate-suite'...\u001b[0m\n\u001b[1m\u001b[31mE   \u2705 Suite 'test-duplicate-suite' created successfully!\u001b[0m\n\u001b[1m\u001b[31mE   Suite ID: test-duplicate-suite\u001b[0m\n\u001b[1m\u001b[31mE   \u001b[0m\n\u001b[1m\u001b[31mE   \ud83d\udca1 Add servers to this suite with:\u001b[0m\n\u001b[1m\u001b[31mE      mcp-ma\u001b[0m\n\u001b[31m\u001b[1m_______________ TestSuiteCreation.test_create_suite_invalid_name _______________\u001b[0m\n\u001b[1m\u001b[31mtests/test_suite_management.py\u001b[0m:98: in test_create_suite_invalid_name\n    \u001b[0mTestAssertions.assert_command_failure(result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mInvalid suite name: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00minvalid_name\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:248: in assert_command_failure\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Invalid suite name: \u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main suite create  --description Invalid name test\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Failure\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Success (returncode 0)\u001b[0m\n\u001b[1m\u001b[31mE   Output: Creating suite '' with ID ''...\u001b[0m\n\u001b[1m\u001b[31mE   \u2705 Suite '' created successfully!\u001b[0m\n\u001b[1m\u001b[31mE   Suite ID: \u001b[0m\n\u001b[1m\u001b[31mE   \u001b[0m\n\u001b[1m\u001b[31mE   \ud83d\udca1 Add servers to this suite with:\u001b[0m\n\u001b[1m\u001b[31mE      mcp-manager suite add  <server-name> --role member --priority 50\u001b[0m\n\u001b[31m\u001b[1m________ TestSuiteServerManagement.test_add_server_to_nonexistent_suite ________\u001b[0m\n\u001b[1m\u001b[31mtests/test_suite_management.py\u001b[0m:208: in test_add_server_to_nonexistent_suite\n    \u001b[0mTestAssertions.assert_command_failure(result, \u001b[33m\"\u001b[39;49;00m\u001b[33mAdd server to nonexistent suite\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:248: in assert_command_failure\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Add server to nonexistent suite\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main suite add nonexistent-suite test-server\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Failure\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Success (returncode 0)\u001b[0m\n\u001b[1m\u001b[31mE   Output: Adding test-server to suite nonexistent-suite as member...\u001b[0m\n\u001b[1m\u001b[31mE   \u274c Failed to add server to suite\u001b[0m\n\u001b[31m\u001b[1m_____ TestSuiteServerManagement.test_remove_server_from_nonexistent_suite ______\u001b[0m\n\u001b[1m\u001b[31mtests/test_suite_management.py\u001b[0m:218: in test_remove_server_from_nonexistent_suite\n    \u001b[0mTestAssertions.assert_command_failure(result, \u001b[33m\"\u001b[39;49;00m\u001b[33mRemove server from nonexistent suite\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:248: in assert_command_failure\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Remove server from nonexistent suite\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main suite remove nonexistent-suite test-server\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Failure\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Success (returncode 0)\u001b[0m\n\u001b[1m\u001b[31mE   Output: Removing test-server from suite nonexistent-suite...\u001b[0m\n\u001b[1m\u001b[31mE   \u274c Failed to remove server from suite\u001b[0m\n\u001b[31m\u001b[1m__________ TestSuiteListing.test_list_suites_by_category[development] __________\u001b[0m\n\u001b[1m\u001b[31mtests/test_suite_management.py\u001b[0m:277: in test_list_suites_by_category\n    \u001b[0mTestAssertions.assert_contains_all(\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:290: in assert_contains_all\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Category filter shows development suite\u001b[0m\n\u001b[1m\u001b[31mE   Missing items: ['development-suite']\u001b[0m\n\u001b[1m\u001b[31mE   In text: \u001b[0m\n\u001b[1m\u001b[31mE                             MCP Server Suites (1 total)                           \u001b[0m\n\u001b[1m\u001b[31mE   \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\u001b[0m\n\u001b[1m\u001b[31mE   \u2503 Suite ID    \u2503 Name             \u2503 Categ\u2026 \u2503  \u2503 Description                     \u2503\u001b[0m\n\u001b[1m\u001b[31mE   \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\n\u001b[31m\u001b[1m_______ TestSuiteInstallation.test_suite_installation_nonexistent_suite ________\u001b[0m\n\u001b[1m\u001b[31mtests/test_suite_management.py\u001b[0m:450: in test_suite_installation_nonexistent_suite\n    \u001b[0mTestAssertions.assert_command_failure(result, \u001b[33m\"\u001b[39;49;00m\u001b[33mInstall nonexistent suite\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:248: in assert_command_failure\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Install nonexistent suite\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main install-suite --suite-name nonexistent-suite\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Failure\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Success (returncode 0)\u001b[0m\n\u001b[1m\u001b[31mE   Output: \u274c Suite 'nonexistent-suite' not found\u001b[0m\n\u001b[1m\u001b[31mE   \ud83d\udca1 Available suites:\u001b[0m\n- generated xml file: /Users/jestes/mcp-manager/tests/results/test-results-suite-management.xml -\n============================= slowest 10 durations =============================\n1.91s call     tests/test_suite_management.py::TestSuiteWorkflows::test_complete_suite_lifecycle\n1.63s call     tests/test_suite_management.py::TestSuiteInstallation::test_suite_installation_actual\n1.23s call     tests/test_suite_management.py::TestSuiteServerManagement::test_add_multiple_servers_to_suite\n1.22s call     tests/test_suite_management.py::TestSuiteServerManagement::test_remove_server_from_suite\n1.05s call     tests/test_suite_management.py::TestSuiteDetails::test_show_suite_details\n1.02s call     tests/test_suite_management.py::TestSuiteListing::test_suite_summary\n0.88s call     tests/test_suite_management.py::TestSuiteInstallation::test_suite_installation_options[--force]\n0.88s call     tests/test_suite_management.py::TestSuiteServerManagement::test_add_server_to_suite\n0.69s call     tests/test_suite_management.py::TestSuiteInstallation::test_suite_installation_dry_run\n0.69s call     tests/test_suite_management.py::TestSuiteListing::test_list_suites_by_category[production]\n\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n\u001b[31mFAILED\u001b[0m tests/test_suite_management.py::\u001b[1mTestSuiteCreation::test_create_duplicate_suite\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_suite_management.py::\u001b[1mTestSuiteCreation::test_create_suite_invalid_name\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_suite_management.py::\u001b[1mTestSuiteServerManagement::test_add_server_to_nonexistent_suite\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_suite_management.py::\u001b[1mTestSuiteServerManagement::test_remove_server_from_nonexistent_suite\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_suite_management.py::\u001b[1mTestSuiteListing::test_list_suites_by_category[development]\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_suite_management.py::\u001b[1mTestSuiteInstallation::test_suite_installation_nonexistent_suite\u001b[0m - AssertionError: \n\u001b[31m======================== \u001b[31m\u001b[1m6 failed\u001b[0m, \u001b[32m27 passed\u001b[0m\u001b[31m in 19.04s\u001b[0m\u001b[31m =========================\u001b[0m\n",
      "stderr": "",
      "command": "python -m pytest tests/test_suite_management.py --verbose --tb=short --durations=10 --junitxml=tests/results/test-results-suite-management.xml --color=yes -s"
    },
    {
      "category": "Quality Tracking",
      "success": false,
      "returncode": 1,
      "duration": 22.094997882843018,
      "stdout": "\u001b[1m============================= test session starts ==============================\u001b[0m\nplatform darwin -- Python 3.12.7, pytest-8.4.1, pluggy-1.6.0 -- /opt/homebrew/anaconda3/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.7', 'Platform': 'macOS-15.5-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'flask': '1.3.0', 'html': '4.1.1', 'xdist': '3.8.0', 'metadata': '3.1.1', 'cov': '6.2.1', 'asyncio': '1.0.0'}}\nrootdir: /Users/jestes/mcp-manager\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, flask-1.3.0, html-4.1.1, xdist-3.8.0, metadata-3.1.1, cov-6.2.1, asyncio-1.0.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\n\u001b[1mcollecting ... \u001b[0mcollected 27 items\n\ntests/test_quality_tracking.py::TestQualityStatus::test_quality_status_basic \u001b[31mFAILED\u001b[0m\ntests/test_quality_tracking.py::TestQualityStatus::test_quality_status_empty_system \u001b[32mPASSED\u001b[0m\ntests/test_quality_tracking.py::TestQualityStatus::test_quality_status_verbose \u001b[32mPASSED\u001b[0m\ntests/test_quality_tracking.py::TestQualityRankings::test_quality_rankings_basic \u001b[32mPASSED\u001b[0m\ntests/test_quality_tracking.py::TestQualityRankings::test_quality_rankings_with_limit \u001b[32mPASSED\u001b[0m\ntests/test_quality_tracking.py::TestQualityRankings::test_quality_rankings_by_metric \u001b[32mPASSED\u001b[0m\ntests/test_quality_tracking.py::TestQualityRankings::test_quality_rankings_category_filter \u001b[32mPASSED\u001b[0m\ntests/test_quality_tracking.py::TestQualityFeedback::test_record_quality_feedback_basic \u001b[31mFAILED\u001b[0m\ntests/test_quality_tracking.py::TestQualityFeedback::test_record_feedback_different_ratings[1] \u001b[31mFAILED\u001b[0m\ntests/test_quality_tracking.py::TestQualityFeedback::test_record_feedback_different_ratings[2] \u001b[31mFAILED\u001b[0m\ntests/test_quality_tracking.py::TestQualityFeedback::test_record_feedback_different_ratings[3] \u001b[31mFAILED\u001b[0m\ntests/test_quality_tracking.py::TestQualityFeedback::test_record_feedback_different_ratings[4] \u001b[31mFAILED\u001b[0m\ntests/test_quality_tracking.py::TestQualityFeedback::test_record_feedback_different_ratings[5] \u001b[31mFAILED\u001b[0m\ntests/test_quality_tracking.py::TestQualityFeedback::test_record_feedback_with_detailed_comment \u001b[31mFAILED\u001b[0m\ntests/test_quality_tracking.py::TestQualityFeedback::test_record_feedback_invalid_rating \u001b[32mPASSED\u001b[0m\ntests/test_quality_tracking.py::TestQualityFeedback::test_record_feedback_nonexistent_server \u001b[31mFAILED\u001b[0m\ntests/test_quality_tracking.py::TestQualityFeedback::test_record_feedback_missing_comment \u001b[31mFAILED\u001b[0m\ntests/test_quality_tracking.py::TestQualityReports::test_quality_report_basic \u001b[31mFAILED\u001b[0m\ntests/test_quality_tracking.py::TestQualityReports::test_quality_report_specific_server \u001b[32mPASSED\u001b[0m\ntests/test_quality_tracking.py::TestQualityReports::test_quality_report_date_range \u001b[32mPASSED\u001b[0m\ntests/test_quality_tracking.py::TestQualityReports::test_quality_report_export_formats \u001b[32mPASSED\u001b[0m\ntests/test_quality_tracking.py::TestQualityMetrics::test_quality_metrics_calculation \u001b[32mPASSED\u001b[0m\ntests/test_quality_tracking.py::TestQualityMetrics::test_quality_trends_tracking \u001b[32mPASSED\u001b[0m\ntests/test_quality_tracking.py::TestQualityIntegration::test_quality_integration_with_discovery \u001b[32mPASSED\u001b[0m\ntests/test_quality_tracking.py::TestQualityIntegration::test_quality_integration_with_suite_installation \u001b[32mPASSED\u001b[0m\ntests/test_quality_tracking.py::TestQualityWorkflows::test_complete_quality_workflow \u001b[31mFAILED\u001b[0m\ntests/test_quality_tracking.py::TestQualityWorkflows::test_bulk_quality_feedback \u001b[31mFAILED\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m_________________ TestQualityStatus.test_quality_status_basic __________________\u001b[0m\n\u001b[1m\u001b[31mtests/test_quality_tracking.py\u001b[0m:21: in test_quality_status_basic\n    \u001b[0m\u001b[94massert\u001b[39;49;00m OutputValidator.validate_status_output(result[\u001b[33m'\u001b[39;49;00m\u001b[33mstdout\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   assert False\u001b[0m\n\u001b[1m\u001b[31mE    +  where False = <function OutputValidator.validate_status_output at 0x104715a80>(\"\ud83d\udcca Quality Tracking Status\\\\n\\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \ud83d\udcc8 Overall Statistics \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502 Tracked Servers: 3                                                           \u2502\\n\u2502 With Quality Data: 3                                                         \u2502\\n\u2502 Total Install Attempts: 22                                                   \u2502\\n\u2502 Overall Success Rate: 68.2%                                                  \u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\\\\nQuality Distribution:\\n\u256d\u2500\u2500\u2500 Good \u2500\u2500\u2500\u2500\u256e \u256d\u2500\u2500\u2500 Fair \u2500\u2500\u2500\u2500\u256e \u256d\u2500\u2500\u2500 Poor \u2500\u2500\u2500\u2500\u256e\\n\u2502 \u2705 1        \u2502 \u2502 \u26a0\ufe0f 1         \u2502 \u2502 \u2757 1        \u2502\\n\u2502 servers\\\\n(\u2026 \u2502 \u2502 servers\\\\n(\u2026 \u2502 \u2502 servers\\\\n(\u2026 \u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\\\\n\ud83d\udca1 Use 'mcp-manager quality rankings' to see detailed server rankings\\n\")\u001b[0m\n\u001b[1m\u001b[31mE    +    where <function OutputValidator.validate_status_output at 0x104715a80> = OutputValidator.validate_status_output\u001b[0m\n\u001b[31m\u001b[1m____________ TestQualityFeedback.test_record_quality_feedback_basic ____________\u001b[0m\n\u001b[1m\u001b[31mtests/test_quality_tracking.py\u001b[0m:104: in test_record_quality_feedback_basic\n    \u001b[0mTestAssertions.assert_command_success(result, \u001b[33m\"\u001b[39;49;00m\u001b[33mRecord quality feedback\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Record quality feedback\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback test-feedback-server test-install-id --rating 4 --comment Works well\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m________ TestQualityFeedback.test_record_feedback_different_ratings[1] _________\u001b[0m\n\u001b[1m\u001b[31mtests/test_quality_tracking.py\u001b[0m:124: in test_record_feedback_different_ratings\n    \u001b[0mTestAssertions.assert_command_success(result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mFeedback rating \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mrating\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Feedback rating 1\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback test-rating-1-server test-rating-1-id --rating 1 --comment Rating 1 test\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m________ TestQualityFeedback.test_record_feedback_different_ratings[2] _________\u001b[0m\n\u001b[1m\u001b[31mtests/test_quality_tracking.py\u001b[0m:124: in test_record_feedback_different_ratings\n    \u001b[0mTestAssertions.assert_command_success(result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mFeedback rating \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mrating\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Feedback rating 2\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback test-rating-2-server test-rating-2-id --rating 2 --comment Rating 2 test\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m________ TestQualityFeedback.test_record_feedback_different_ratings[3] _________\u001b[0m\n\u001b[1m\u001b[31mtests/test_quality_tracking.py\u001b[0m:124: in test_record_feedback_different_ratings\n    \u001b[0mTestAssertions.assert_command_success(result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mFeedback rating \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mrating\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Feedback rating 3\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback test-rating-3-server test-rating-3-id --rating 3 --comment Rating 3 test\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m________ TestQualityFeedback.test_record_feedback_different_ratings[4] _________\u001b[0m\n\u001b[1m\u001b[31mtests/test_quality_tracking.py\u001b[0m:124: in test_record_feedback_different_ratings\n    \u001b[0mTestAssertions.assert_command_success(result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mFeedback rating \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mrating\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Feedback rating 4\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback test-rating-4-server test-rating-4-id --rating 4 --comment Rating 4 test\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m________ TestQualityFeedback.test_record_feedback_different_ratings[5] _________\u001b[0m\n\u001b[1m\u001b[31mtests/test_quality_tracking.py\u001b[0m:124: in test_record_feedback_different_ratings\n    \u001b[0mTestAssertions.assert_command_success(result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mFeedback rating \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mrating\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Feedback rating 5\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback test-rating-5-server test-rating-5-id --rating 5 --comment Rating 5 test\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m________ TestQualityFeedback.test_record_feedback_with_detailed_comment ________\u001b[0m\n\u001b[1m\u001b[31mtests/test_quality_tracking.py\u001b[0m:144: in test_record_feedback_with_detailed_comment\n    \u001b[0mTestAssertions.assert_command_success(result, \u001b[33m\"\u001b[39;49;00m\u001b[33mDetailed feedback comment\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Detailed feedback comment\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback test-detailed-feedback-server test-detailed-id --rating 5 --comment This server works excellently for filesystem operations. Installation was smooth, performance is great, and documentation is comprehensive.\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m_________ TestQualityFeedback.test_record_feedback_nonexistent_server __________\u001b[0m\n\u001b[1m\u001b[31mtests/test_quality_tracking.py\u001b[0m:167: in test_record_feedback_nonexistent_server\n    \u001b[0mTestAssertions.assert_command_failure(result, \u001b[33m\"\u001b[39;49;00m\u001b[33mFeedback for nonexistent server\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:248: in assert_command_failure\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Feedback for nonexistent server\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback nonexistent-server test-id --rating 4 --comment Test\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Failure\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Success (returncode 2)\u001b[0m\n\u001b[1m\u001b[31mE   Output:\u001b[0m\n\u001b[31m\u001b[1m___________ TestQualityFeedback.test_record_feedback_missing_comment ___________\u001b[0m\n\u001b[1m\u001b[31mtests/test_quality_tracking.py\u001b[0m:189: in test_record_feedback_missing_comment\n    \u001b[0mTestAssertions.assert_command_success(result, \u001b[33m\"\u001b[39;49;00m\u001b[33mFeedback without comment\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Feedback without comment\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback test-no-comment-server test-no-comment-id --rating 4\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m_________________ TestQualityReports.test_quality_report_basic _________________\u001b[0m\n\u001b[1m\u001b[31mtests/test_quality_tracking.py\u001b[0m:199: in test_quality_report_basic\n    \u001b[0mTestAssertions.assert_command_success(result, \u001b[33m\"\u001b[39;49;00m\u001b[33mQuality report basic\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Quality report basic\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality report\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m_____________ TestQualityWorkflows.test_complete_quality_workflow ______________\u001b[0m\n\u001b[1m\u001b[31mtests/test_quality_tracking.py\u001b[0m:400: in test_complete_quality_workflow\n    \u001b[0mTestAssertions.assert_command_success(feedback_result, \u001b[33m\"\u001b[39;49;00m\u001b[33mQuality workflow: Record feedback\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Quality workflow: Record feedback\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback test-quality-workflow-server test-workflow-id --rating 4 --comment Initial feedback\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m_______________ TestQualityWorkflows.test_bulk_quality_feedback ________________\u001b[0m\n\u001b[1m\u001b[31mtests/test_quality_tracking.py\u001b[0m:446: in test_bulk_quality_feedback\n    \u001b[0mTestAssertions.assert_command_success(feedback_result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mBulk feedback: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mserver_name\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Bulk feedback: bulk-server-1\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback bulk-server-1 bulk-test-id --rating 5 --comment Excellent performance\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n- generated xml file: /Users/jestes/mcp-manager/tests/results/test-results-quality-tracking.xml -\n============================= slowest 10 durations =============================\n1.91s call     tests/test_quality_tracking.py::TestQualityMetrics::test_quality_metrics_calculation\n1.60s call     tests/test_quality_tracking.py::TestQualityIntegration::test_quality_integration_with_suite_installation\n1.58s call     tests/test_quality_tracking.py::TestQualityMetrics::test_quality_trends_tracking\n1.25s call     tests/test_quality_tracking.py::TestQualityReports::test_quality_report_specific_server\n1.09s call     tests/test_quality_tracking.py::TestQualityWorkflows::test_complete_quality_workflow\n1.08s call     tests/test_quality_tracking.py::TestQualityFeedback::test_record_feedback_different_ratings[4]\n1.08s call     tests/test_quality_tracking.py::TestQualityFeedback::test_record_feedback_different_ratings[5]\n1.08s call     tests/test_quality_tracking.py::TestQualityFeedback::test_record_feedback_missing_comment\n1.08s call     tests/test_quality_tracking.py::TestQualityFeedback::test_record_feedback_different_ratings[1]\n1.08s call     tests/test_quality_tracking.py::TestQualityFeedback::test_record_feedback_different_ratings[3]\n\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n\u001b[31mFAILED\u001b[0m tests/test_quality_tracking.py::\u001b[1mTestQualityStatus::test_quality_status_basic\u001b[0m - assert False\n\u001b[31mFAILED\u001b[0m tests/test_quality_tracking.py::\u001b[1mTestQualityFeedback::test_record_quality_feedback_basic\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_quality_tracking.py::\u001b[1mTestQualityFeedback::test_record_feedback_different_ratings[1]\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_quality_tracking.py::\u001b[1mTestQualityFeedback::test_record_feedback_different_ratings[2]\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_quality_tracking.py::\u001b[1mTestQualityFeedback::test_record_feedback_different_ratings[3]\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_quality_tracking.py::\u001b[1mTestQualityFeedback::test_record_feedback_different_ratings[4]\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_quality_tracking.py::\u001b[1mTestQualityFeedback::test_record_feedback_different_ratings[5]\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_quality_tracking.py::\u001b[1mTestQualityFeedback::test_record_feedback_with_detailed_comment\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_quality_tracking.py::\u001b[1mTestQualityFeedback::test_record_feedback_nonexistent_server\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_quality_tracking.py::\u001b[1mTestQualityFeedback::test_record_feedback_missing_comment\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_quality_tracking.py::\u001b[1mTestQualityReports::test_quality_report_basic\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_quality_tracking.py::\u001b[1mTestQualityWorkflows::test_complete_quality_workflow\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_quality_tracking.py::\u001b[1mTestQualityWorkflows::test_bulk_quality_feedback\u001b[0m - AssertionError: \n\u001b[31m======================== \u001b[31m\u001b[1m13 failed\u001b[0m, \u001b[32m14 passed\u001b[0m\u001b[31m in 21.91s\u001b[0m\u001b[31m ========================\u001b[0m\n",
      "stderr": "",
      "command": "python -m pytest tests/test_quality_tracking.py --verbose --tb=short --durations=10 --junitxml=tests/results/test-results-quality-tracking.xml --color=yes -s"
    },
    {
      "category": "Error Handling",
      "success": false,
      "returncode": 1,
      "duration": 46.61321306228638,
      "stdout": "\u001b[1m============================= test session starts ==============================\u001b[0m\nplatform darwin -- Python 3.12.7, pytest-8.4.1, pluggy-1.6.0 -- /opt/homebrew/anaconda3/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.7', 'Platform': 'macOS-15.5-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'flask': '1.3.0', 'html': '4.1.1', 'xdist': '3.8.0', 'metadata': '3.1.1', 'cov': '6.2.1', 'asyncio': '1.0.0'}}\nrootdir: /Users/jestes/mcp-manager\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, flask-1.3.0, html-4.1.1, xdist-3.8.0, metadata-3.1.1, cov-6.2.1, asyncio-1.0.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\n\u001b[1mcollecting ... \u001b[0mcollected 24 items\n\ntests/test_error_handling.py::TestInvalidCommands::test_completely_invalid_command \u001b[32mPASSED\u001b[0m\ntests/test_error_handling.py::TestInvalidCommands::test_invalid_subcommands \u001b[31mFAILED\u001b[0m\ntests/test_error_handling.py::TestInvalidCommands::test_malformed_command_syntax \u001b[32mPASSED\u001b[0m\ntests/test_error_handling.py::TestInvalidCommands::test_missing_required_arguments \u001b[32mPASSED\u001b[0m\ntests/test_error_handling.py::TestInvalidCommands::test_conflicting_arguments \u001b[31mFAILED\u001b[0m\ntests/test_error_handling.py::TestNonexistentResources::test_nonexistent_server_operations \u001b[31mFAILED\u001b[0m\ntests/test_error_handling.py::TestNonexistentResources::test_nonexistent_suite_operations \u001b[32mPASSED\u001b[0m\ntests/test_error_handling.py::TestNonexistentResources::test_nonexistent_package_installation \u001b[32mPASSED\u001b[0m\ntests/test_error_handling.py::TestInvalidDataFormats::test_invalid_server_names \u001b[31mFAILED\u001b[0m\ntests/test_error_handling.py::TestInvalidDataFormats::test_invalid_suite_names \u001b[31mFAILED\u001b[0m\ntests/test_error_handling.py::TestInvalidDataFormats::test_invalid_quality_ratings \u001b[32mPASSED\u001b[0m\ntests/test_error_handling.py::TestResourceLimits::test_extremely_long_names \u001b[31mFAILED\u001b[0m\ntests/test_error_handling.py::TestResourceLimits::test_extremely_long_descriptions \u001b[32mPASSED\u001b[0m\ntests/test_error_handling.py::TestResourceLimits::test_many_servers_in_suite \u001b[32mPASSED\u001b[0m\ntests/test_error_handling.py::TestConcurrentOperations::test_rapid_server_operations \u001b[32mPASSED\u001b[0m\ntests/test_error_handling.py::TestConcurrentOperations::test_rapid_suite_operations \u001b[32mPASSED\u001b[0m\ntests/test_error_handling.py::TestSystemResourceHandling::test_filesystem_permissions \u001b[32mPASSED\u001b[0m\ntests/test_error_handling.py::TestSystemResourceHandling::test_network_timeout_handling \u001b[32mPASSED\u001b[0m\ntests/test_error_handling.py::TestSystemResourceHandling::test_large_output_handling \u001b[32mPASSED\u001b[0m\ntests/test_error_handling.py::TestEdgeCaseInputs::test_unicode_and_special_characters \u001b[32mPASSED\u001b[0m\ntests/test_error_handling.py::TestEdgeCaseInputs::test_empty_and_whitespace_inputs \u001b[31mFAILED\u001b[0m\ntests/test_error_handling.py::TestRegressionScenarios::test_suite_installation_regression \u001b[32mPASSED\u001b[0m\ntests/test_error_handling.py::TestRegressionScenarios::test_command_help_consistency \u001b[32mPASSED\u001b[0m\ntests/test_error_handling.py::TestRegressionScenarios::test_error_message_quality \u001b[32mPASSED\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m_________________ TestInvalidCommands.test_invalid_subcommands _________________\u001b[0m\n\u001b[1m\u001b[31mtests/test_error_handling.py\u001b[0m:40: in test_invalid_subcommands\n    \u001b[0mTestAssertions.assert_command_failure(result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mInvalid subcommand: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcmd\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:248: in assert_command_failure\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Invalid subcommand: add invalid-server-action\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main add invalid-server-action\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Failure\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Success (returncode 0)\u001b[0m\n\u001b[1m\u001b[31mE   Output: \u274c Failed to add server: Failed to add server invalid-server-action: 1 \u001b[0m\n\u001b[1m\u001b[31mE   validation error for Server\u001b[0m\n\u001b[1m\u001b[31mE   command\u001b[0m\n\u001b[1m\u001b[31mE     Value error, Server command cannot be empty \u001b[0m\n\u001b[1m\u001b[31mE       For further information visit https://erro\u001b[0m\n\u001b[31m\u001b[1m________________ TestInvalidCommands.test_conflicting_arguments ________________\u001b[0m\n\u001b[1m\u001b[31mtests/test_error_handling.py\u001b[0m:90: in test_conflicting_arguments\n    \u001b[0mTestAssertions.assert_command_failure(result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mConflicting args: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcmd\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:248: in assert_command_failure\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Conflicting args: discover --type npm --type docker\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main discover --type npm --type docker\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Failure\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Success (returncode 0)\u001b[0m\n\u001b[1m\u001b[31mE   Output: \u001b[0m\n\u001b[1m\u001b[31mE                         Discovered MCP Servers (20 results)                       \u001b[0m\n\u001b[1m\u001b[31mE   \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\u001b[0m\n\u001b[1m\u001b[31mE   \u2503 Install ID    \u2503\u2503 Name/Package\u001b[0m\n\u001b[31m\u001b[1m_________ TestNonexistentResources.test_nonexistent_server_operations __________\u001b[0m\n\u001b[1m\u001b[31mtests/test_error_handling.py\u001b[0m:114: in test_nonexistent_server_operations\n    \u001b[0m\u001b[94massert\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mnot found\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m result[\u001b[33m'\u001b[39;49;00m\u001b[33mstdout\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].lower() \u001b[95mor\u001b[39;49;00m \\\n\u001b[1m\u001b[31mE   assert ('not found' in \"remove server 'nonexistent-server-xyz'? [y/n]: failed to remove server: eof when reading a line\\n\" or 'does not exist' in \"remove server 'nonexistent-server-xyz'? [y/n]: failed to remove server: eof when reading a line\\n\")\u001b[0m\n\u001b[1m\u001b[31mE    +  where \"remove server 'nonexistent-server-xyz'? [y/n]: failed to remove server: eof when reading a line\\n\" = <built-in method lower of str object at 0x103316670>()\u001b[0m\n\u001b[1m\u001b[31mE    +    where <built-in method lower of str object at 0x103316670> = \"Remove server 'nonexistent-server-xyz'? [y/n]: Failed to remove server: EOF when reading a line\\n\".lower\u001b[0m\n\u001b[1m\u001b[31mE    +  and   \"remove server 'nonexistent-server-xyz'? [y/n]: failed to remove server: eof when reading a line\\n\" = <built-in method lower of str object at 0x103316670>()\u001b[0m\n\u001b[1m\u001b[31mE    +    where <built-in method lower of str object at 0x103316670> = \"Remove server 'nonexistent-server-xyz'? [y/n]: Failed to remove server: EOF when reading a line\\n\".lower\u001b[0m\n\u001b[31m\u001b[1m_______________ TestInvalidDataFormats.test_invalid_server_names _______________\u001b[0m\n\u001b[1m\u001b[31mtests/test_error_handling.py\u001b[0m:182: in test_invalid_server_names\n    \u001b[0mTestAssertions.assert_command_failure(result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mInvalid server name: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mrepr\u001b[39;49;00m(name)\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:248: in assert_command_failure\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Invalid server name: ''\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main add  --type custom --command echo test\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Failure\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Success (returncode 0)\u001b[0m\n\u001b[1m\u001b[31mE   Output: \u274c Failed to add server: Failed to add server : 1 validation error for Server\u001b[0m\n\u001b[1m\u001b[31mE   name\u001b[0m\n\u001b[1m\u001b[31mE     Value error, Server name cannot be empty \u001b[0m\n\u001b[1m\u001b[31mE       For further information visit https://errors.pydantic.dev/2.11/v/value\u001b[0m\n\u001b[31m\u001b[1m_______________ TestInvalidDataFormats.test_invalid_suite_names ________________\u001b[0m\n\u001b[1m\u001b[31mtests/test_error_handling.py\u001b[0m:201: in test_invalid_suite_names\n    \u001b[0mTestAssertions.assert_command_failure(result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mInvalid suite name: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mrepr\u001b[39;49;00m(name)\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:248: in assert_command_failure\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Invalid suite name: ''\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main suite create  --description Test suite\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Failure\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Success (returncode 0)\u001b[0m\n\u001b[1m\u001b[31mE   Output: Creating suite '' with ID ''...\u001b[0m\n\u001b[1m\u001b[31mE   \u2705 Suite '' created successfully!\u001b[0m\n\u001b[1m\u001b[31mE   Suite ID: \u001b[0m\n\u001b[1m\u001b[31mE   \u001b[0m\n\u001b[1m\u001b[31mE   \ud83d\udca1 Add servers to this suite with:\u001b[0m\n\u001b[1m\u001b[31mE      mcp-manager suite add  <server-name> --role member --priority 50\u001b[0m\n\u001b[31m\u001b[1m_________________ TestResourceLimits.test_extremely_long_names _________________\u001b[0m\n\u001b[1m\u001b[31mtests/test_error_handling.py\u001b[0m:245: in test_extremely_long_names\n    \u001b[0mTestAssertions.assert_command_failure(result, \u001b[33m\"\u001b[39;49;00m\u001b[33mExtremely long server name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:248: in assert_command_failure\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Extremely long server name\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main add aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa --type custom --command echo test\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Failure\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Success (returncode 0)\u001b[0m\n\u001b[1m\u001b[31mE   Output: \u274c Failed to add server: Failed to add server \u001b[0m\n\u001b[1m\u001b[31mE   aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\u001b[0m\n\u001b[1m\u001b[31mE   aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\u001b[0m\n\u001b[31m\u001b[1m_____________ TestEdgeCaseInputs.test_empty_and_whitespace_inputs ______________\u001b[0m\n\u001b[1m\u001b[31mtests/test_error_handling.py\u001b[0m:429: in test_empty_and_whitespace_inputs\n    \u001b[0mTestAssertions.assert_command_failure(result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mEmpty input: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[96mrepr\u001b[39;49;00m(empty_input)\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:248: in assert_command_failure\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Empty input: ''\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main add  --type custom --command echo test\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Failure\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Success (returncode 0)\u001b[0m\n\u001b[1m\u001b[31mE   Output: \u274c Failed to add server: Failed to add server : 1 validation error for Server\u001b[0m\n\u001b[1m\u001b[31mE   name\u001b[0m\n\u001b[1m\u001b[31mE     Value error, Server name cannot be empty \u001b[0m\n\u001b[1m\u001b[31mE       For further information visit https://errors.pydantic.dev/2.11/v/value\u001b[0m\n- generated xml file: /Users/jestes/mcp-manager/tests/results/test-results-error-handling.xml -\n============================= slowest 10 durations =============================\n10.27s call     tests/test_error_handling.py::TestConcurrentOperations::test_rapid_server_operations\n9.30s call     tests/test_error_handling.py::TestResourceLimits::test_many_servers_in_suite\n4.77s call     tests/test_error_handling.py::TestEdgeCaseInputs::test_unicode_and_special_characters\n3.61s call     tests/test_error_handling.py::TestConcurrentOperations::test_rapid_suite_operations\n2.86s call     tests/test_error_handling.py::TestNonexistentResources::test_nonexistent_package_installation\n1.94s call     tests/test_error_handling.py::TestSystemResourceHandling::test_filesystem_permissions\n1.91s call     tests/test_error_handling.py::TestInvalidDataFormats::test_invalid_quality_ratings\n1.66s call     tests/test_error_handling.py::TestRegressionScenarios::test_command_help_consistency\n1.33s call     tests/test_error_handling.py::TestInvalidCommands::test_missing_required_arguments\n1.05s call     tests/test_error_handling.py::TestRegressionScenarios::test_error_message_quality\n\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n\u001b[31mFAILED\u001b[0m tests/test_error_handling.py::\u001b[1mTestInvalidCommands::test_invalid_subcommands\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_error_handling.py::\u001b[1mTestInvalidCommands::test_conflicting_arguments\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_error_handling.py::\u001b[1mTestNonexistentResources::test_nonexistent_server_operations\u001b[0m - assert ('not found' in \"remove server 'nonexistent-server-xyz'? [y/n]: fail...\n\u001b[31mFAILED\u001b[0m tests/test_error_handling.py::\u001b[1mTestInvalidDataFormats::test_invalid_server_names\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_error_handling.py::\u001b[1mTestInvalidDataFormats::test_invalid_suite_names\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_error_handling.py::\u001b[1mTestResourceLimits::test_extremely_long_names\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_error_handling.py::\u001b[1mTestEdgeCaseInputs::test_empty_and_whitespace_inputs\u001b[0m - AssertionError: \n\u001b[31m======================== \u001b[31m\u001b[1m7 failed\u001b[0m, \u001b[32m17 passed\u001b[0m\u001b[31m in 46.43s\u001b[0m\u001b[31m =========================\u001b[0m\n",
      "stderr": "",
      "command": "python -m pytest tests/test_error_handling.py --verbose --tb=short --durations=10 --junitxml=tests/results/test-results-error-handling.xml --color=yes -s"
    },
    {
      "category": "Regression Tests",
      "success": true,
      "returncode": 0,
      "duration": 3.4727370738983154,
      "stdout": "\u001b[1m============================= test session starts ==============================\u001b[0m\nplatform darwin -- Python 3.12.7, pytest-8.4.1, pluggy-1.6.0 -- /opt/homebrew/anaconda3/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.7', 'Platform': 'macOS-15.5-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'flask': '1.3.0', 'html': '4.1.1', 'xdist': '3.8.0', 'metadata': '3.1.1', 'cov': '6.2.1', 'asyncio': '1.0.0'}}\nrootdir: /Users/jestes/mcp-manager\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, flask-1.3.0, html-4.1.1, xdist-3.8.0, metadata-3.1.1, cov-6.2.1, asyncio-1.0.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\n\u001b[1mcollecting ... \u001b[0mcollected 151 items / 148 deselected / 3 selected\n\ntests/test_error_handling.py::TestRegressionScenarios::test_suite_installation_regression \u001b[32mPASSED\u001b[0m\ntests/test_error_handling.py::TestRegressionScenarios::test_command_help_consistency \u001b[32mPASSED\u001b[0m\ntests/test_error_handling.py::TestRegressionScenarios::test_error_message_quality \u001b[32mPASSED\u001b[0m\n\n\u001b[33m=============================== warnings summary ===============================\u001b[0m\ntests/tools/test_menu.py:18\n  /Users/jestes/mcp-manager/tests/tools/test_menu.py:18: PytestCollectionWarning: cannot collect test class 'TestMenu' because it has a __init__ constructor (from: tests/tools/test_menu.py)\n    class TestMenu:\n\ntests/utils/test_data_manager.py:15\n  /Users/jestes/mcp-manager/tests/utils/test_data_manager.py:15: PytestCollectionWarning: cannot collect test class 'TestDataManager' because it has a __init__ constructor (from: tests/utils/test_data_manager.py)\n    class TestDataManager:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n- generated xml file: /Users/jestes/mcp-manager/tests/results/test-results-regression-tests.xml -\n============================= slowest 10 durations =============================\n1.66s call     tests/test_error_handling.py::TestRegressionScenarios::test_command_help_consistency\n1.05s call     tests/test_error_handling.py::TestRegressionScenarios::test_error_message_quality\n0.53s call     tests/test_error_handling.py::TestRegressionScenarios::test_suite_installation_regression\n\n(6 durations < 0.005s hidden.  Use -vv to show these durations.)\n\u001b[33m================ \u001b[32m3 passed\u001b[0m, \u001b[33m\u001b[1m148 deselected\u001b[0m, \u001b[33m\u001b[1m2 warnings\u001b[0m\u001b[33m in 3.29s\u001b[0m\u001b[33m =================\u001b[0m\n",
      "stderr": "",
      "command": "python -m pytest tests/ -m regression --verbose --tb=short --durations=10 --junitxml=tests/results/test-results-regression-tests.xml --color=yes -s"
    },
    {
      "category": "Integration Tests",
      "success": false,
      "returncode": 1,
      "duration": 18.8208749294281,
      "stdout": "\u001b[1m============================= test session starts ==============================\u001b[0m\nplatform darwin -- Python 3.12.7, pytest-8.4.1, pluggy-1.6.0 -- /opt/homebrew/anaconda3/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.7', 'Platform': 'macOS-15.5-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'flask': '1.3.0', 'html': '4.1.1', 'xdist': '3.8.0', 'metadata': '3.1.1', 'cov': '6.2.1', 'asyncio': '1.0.0'}}\nrootdir: /Users/jestes/mcp-manager\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, flask-1.3.0, html-4.1.1, xdist-3.8.0, metadata-3.1.1, cov-6.2.1, asyncio-1.0.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\n\u001b[1mcollecting ... \u001b[0mcollected 151 items / 144 deselected / 7 selected\n\ntests/test_quality_tracking.py::TestQualityWorkflows::test_complete_quality_workflow \u001b[31mFAILED\u001b[0m\ntests/test_quality_tracking.py::TestQualityWorkflows::test_bulk_quality_feedback \u001b[31mFAILED\u001b[0m\ntests/test_server_management.py::TestServerLifecycle::test_complete_server_lifecycle \u001b[31mFAILED\u001b[0m\ntests/test_server_management.py::TestServerLifecycle::test_bulk_server_operations \u001b[32mPASSED\u001b[0m\ntests/test_suite_management.py::TestSuiteWorkflows::test_complete_suite_lifecycle \u001b[32mPASSED\u001b[0m\ntests/test_workflows.py::TestComplexIntegrationWorkflows::test_complete_enterprise_deployment_workflow \ud83c\udfe2 Starting Enterprise Deployment Workflow...\n\n\ud83d\udccb Phase 1: Environment Setup\n\n\ud83d\udd0d Phase 2: Server Discovery and Selection\n\n\u2699\ufe0f Phase 3: Environment Configuration\n\n\ud83e\uddea Phase 4: Quality Assurance Testing\n\n\ud83d\udcca Phase 5: Quality Metrics Collection\n\u001b[31mFAILED\u001b[0m\ntests/test_workflows.py::TestComplexIntegrationWorkflows::test_continuous_integration_workflow \ud83d\udd04 Starting Continuous Integration Workflow...\n\n\ud83d\udd27 Phase 1: CI Pipeline Setup\n\n\ud83d\udee0\ufe0f Phase 2: Adding CI Tools\n\n\ud83e\uddea Phase 3: Automated Testing Simulation\n\u001b[31mFAILED\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m_____________ TestQualityWorkflows.test_complete_quality_workflow ______________\u001b[0m\n\u001b[1m\u001b[31mtests/test_quality_tracking.py\u001b[0m:400: in test_complete_quality_workflow\n    \u001b[0mTestAssertions.assert_command_success(feedback_result, \u001b[33m\"\u001b[39;49;00m\u001b[33mQuality workflow: Record feedback\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Quality workflow: Record feedback\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback test-quality-workflow-server test-workflow-id --rating 4 --comment Initial feedback\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m_______________ TestQualityWorkflows.test_bulk_quality_feedback ________________\u001b[0m\n\u001b[1m\u001b[31mtests/test_quality_tracking.py\u001b[0m:446: in test_bulk_quality_feedback\n    \u001b[0mTestAssertions.assert_command_success(feedback_result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mBulk feedback: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mserver_name\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Bulk feedback: bulk-server-1\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback bulk-server-1 bulk-test-id --rating 5 --comment Excellent performance\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m______________ TestServerLifecycle.test_complete_server_lifecycle ______________\u001b[0m\n\u001b[1m\u001b[31mtests/test_server_management.py\u001b[0m:354: in test_complete_server_lifecycle\n    \u001b[0mTestAssertions.assert_contains_all(\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:290: in assert_contains_all\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Lifecycle: Server in list\u001b[0m\n\u001b[1m\u001b[31mE   Missing items: ['test-lifecycle-server']\u001b[0m\n\u001b[1m\u001b[31mE   In text: \u001b[0m\n\u001b[1m\u001b[31mE                                MCP Servers (45 total)                             \u001b[0m\n\u001b[1m\u001b[31mE   \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\u001b[0m\n\u001b[1m\u001b[31mE   \u2503 Name            \u2503 Type    \u2503 Sc\u2026 \u2503 Sta\u2026 \u2503 Command                             \u2503\u001b[0m\n\u001b[1m\u001b[31mE   \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\n\u001b[31m\u001b[1m_ TestComplexIntegrationWorkflows.test_complete_enterprise_deployment_workflow _\u001b[0m\n\u001b[1m\u001b[31mtests/test_workflows.py\u001b[0m:604: in test_complete_enterprise_deployment_workflow\n    \u001b[0mTestAssertions.assert_command_success(feedback_result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mEnterprise: QA feedback \u001b[39;49;00m\u001b[33m{\u001b[39;49;00menv\u001b[33m}\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mserver\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Enterprise: QA feedback development filesystem\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback filesystem enterprise-development --rating 4 --comment Enterprise development deployment\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m_____ TestComplexIntegrationWorkflows.test_continuous_integration_workflow _____\u001b[0m\n\u001b[1m\u001b[31mtests/test_workflows.py\u001b[0m:660: in test_continuous_integration_workflow\n    \u001b[0mTestAssertions.assert_command_success(feedback_result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mCI: Record test \u001b[39;49;00m\u001b[33m{\u001b[39;49;00miteration\u001b[90m \u001b[39;49;00m+\u001b[90m \u001b[39;49;00m\u001b[94m1\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m for \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtool\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: CI: Record test 1 for filesystem\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback filesystem ci-iteration-0 --rating 4 --comment CI test iteration 1\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[33m=============================== warnings summary ===============================\u001b[0m\ntests/tools/test_menu.py:18\n  /Users/jestes/mcp-manager/tests/tools/test_menu.py:18: PytestCollectionWarning: cannot collect test class 'TestMenu' because it has a __init__ constructor (from: tests/tools/test_menu.py)\n    class TestMenu:\n\ntests/utils/test_data_manager.py:15\n  /Users/jestes/mcp-manager/tests/utils/test_data_manager.py:15: PytestCollectionWarning: cannot collect test class 'TestDataManager' because it has a __init__ constructor (from: tests/utils/test_data_manager.py)\n    class TestDataManager:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n- generated xml file: /Users/jestes/mcp-manager/tests/results/test-results-integration-tests.xml -\n============================= slowest 10 durations =============================\n8.36s call     tests/test_server_management.py::TestServerLifecycle::test_bulk_server_operations\n3.07s call     tests/test_workflows.py::TestComplexIntegrationWorkflows::test_complete_enterprise_deployment_workflow\n1.98s call     tests/test_server_management.py::TestServerLifecycle::test_complete_server_lifecycle\n1.93s call     tests/test_suite_management.py::TestSuiteWorkflows::test_complete_suite_lifecycle\n1.09s call     tests/test_quality_tracking.py::TestQualityWorkflows::test_complete_quality_workflow\n1.08s call     tests/test_quality_tracking.py::TestQualityWorkflows::test_bulk_quality_feedback\n1.03s call     tests/test_workflows.py::TestComplexIntegrationWorkflows::test_continuous_integration_workflow\n\n(3 durations < 0.005s hidden.  Use -vv to show these durations.)\n\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n\u001b[31mFAILED\u001b[0m tests/test_quality_tracking.py::\u001b[1mTestQualityWorkflows::test_complete_quality_workflow\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_quality_tracking.py::\u001b[1mTestQualityWorkflows::test_bulk_quality_feedback\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_server_management.py::\u001b[1mTestServerLifecycle::test_complete_server_lifecycle\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_workflows.py::\u001b[1mTestComplexIntegrationWorkflows::test_complete_enterprise_deployment_workflow\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_workflows.py::\u001b[1mTestComplexIntegrationWorkflows::test_continuous_integration_workflow\u001b[0m - AssertionError: \n\u001b[31m=========== \u001b[31m\u001b[1m5 failed\u001b[0m, \u001b[32m2 passed\u001b[0m, \u001b[33m144 deselected\u001b[0m, \u001b[33m2 warnings\u001b[0m\u001b[31m in 18.63s\u001b[0m\u001b[31m ===========\u001b[0m\n",
      "stderr": "",
      "command": "python -m pytest tests/ -m integration --verbose --tb=short --durations=10 --junitxml=tests/results/test-results-integration-tests.xml --color=yes -s"
    },
    {
      "category": "User Workflows",
      "success": false,
      "returncode": 1,
      "duration": 31.549725770950317,
      "stdout": "\u001b[1m============================= test session starts ==============================\u001b[0m\nplatform darwin -- Python 3.12.7, pytest-8.4.1, pluggy-1.6.0 -- /opt/homebrew/anaconda3/bin/python\ncachedir: .pytest_cache\nmetadata: {'Python': '3.12.7', 'Platform': 'macOS-15.5-arm64-arm-64bit', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'flask': '1.3.0', 'html': '4.1.1', 'xdist': '3.8.0', 'metadata': '3.1.1', 'cov': '6.2.1', 'asyncio': '1.0.0'}}\nrootdir: /Users/jestes/mcp-manager\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, flask-1.3.0, html-4.1.1, xdist-3.8.0, metadata-3.1.1, cov-6.2.1, asyncio-1.0.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\n\u001b[1mcollecting ... \u001b[0mcollected 12 items\n\ntests/test_workflows.py::TestUserOnboardingWorkflows::test_new_user_discovery_to_installation \ud83d\udd0d Step 1: Discovering available MCP servers...\n\ud83d\udd0d Step 2: Exploring filesystem servers...\n\ud83d\udd27 Step 3: Installing a server package...\n\ud83d\udd27 Step 4: Adding custom server...\n\ud83d\udccb Step 5: Viewing configured servers...\n\u2139\ufe0f Step 6: Checking system status...\n\u2705 New user onboarding workflow completed successfully!\n\u001b[32mPASSED\u001b[0m\ntests/test_workflows.py::TestUserOnboardingWorkflows::test_developer_workflow_suite_creation \ud83c\udfd7\ufe0f Step 1: Creating development environment suite...\n\ud83d\udd27 Step 2: Adding development servers to suite...\n\ud83d\udccb Step 3: Reviewing suite configuration...\n\ud83e\uddea Step 4: Testing suite installation...\n\ud83d\udcdd Step 5: Recording server feedback...\n\u001b[31mFAILED\u001b[0m\ntests/test_workflows.py::TestUserOnboardingWorkflows::test_admin_bulk_management_workflow \ud83d\udd0d Step 1: Admin discovering all available servers...\n\ud83c\udfd7\ufe0f Step 2: Creating environment-specific suites...\n\ud83d\udd27 Step 3: Configuring environment-specific servers...\n\ud83d\udccb Step 4: Reviewing all suite configurations...\n\ud83d\udcca Step 5: Checking system-wide quality status...\n\ud83d\udcc8 Step 6: Generating system report...\n\u001b[31mFAILED\u001b[0m\ntests/test_workflows.py::TestProblemSolvingWorkflows::test_troubleshooting_workflow \ud83d\udea8 Step 1: User discovers configuration issue...\n\ud83d\udd0d Step 2: Checking system status for diagnosis...\n\ud83d\udccb Step 3: Examining server configuration...\n\u001b[31mFAILED\u001b[0m\ntests/test_workflows.py::TestProblemSolvingWorkflows::test_performance_optimization_workflow \ud83d\ude80 Step 1: Creating performance-optimized suite...\n\u26a1 Step 2: Adding servers with performance priorities...\n\ud83d\udcca Step 3: Recording performance metrics...\n\u001b[31mFAILED\u001b[0m\ntests/test_workflows.py::TestProblemSolvingWorkflows::test_migration_workflow \ud83d\udce6 Step 1: Setting up old configuration...\n\ud83d\udd04 Step 2: Planning migration to new configuration...\n\u2728 Step 3: Adding modern server configuration...\n\ud83e\uddea Step 4: Testing new configuration...\n\ud83d\udcdd Step 5: Recording migration feedback...\n\u001b[31mFAILED\u001b[0m\ntests/test_workflows.py::TestCollaborationWorkflows::test_team_development_workflow \ud83d\udc65 Step 1: Team lead creates shared development suite...\n\ud83d\udee0\ufe0f Step 2: Adding core development tools...\n\ud83d\udcdd Step 3: Team members providing feedback...\n\u001b[31mFAILED\u001b[0m\ntests/test_workflows.py::TestCollaborationWorkflows::test_project_handoff_workflow \ud83d\udccb Step 1: Original team creates project configuration...\n\ud83d\udcdd Step 2: Documenting project configuration...\n\u001b[31mFAILED\u001b[0m\ntests/test_workflows.py::TestMaintenanceWorkflows::test_routine_maintenance_workflow \ud83d\udd0d Step 1: Checking overall system status...\n\ud83d\udcca Step 2: Reviewing system quality metrics...\n\ud83d\udd04 Step 3: Updating server catalog...\n\ud83d\udcc8 Step 4: Reviewing server quality rankings...\n\ud83d\udccb Step 5: Generating maintenance report...\n\u001b[31mFAILED\u001b[0m\ntests/test_workflows.py::TestMaintenanceWorkflows::test_emergency_recovery_workflow \ud83d\udea8 Step 1: Emergency situation - problematic configuration detected...\n\ud83d\udd0d Step 2: Quick system assessment...\n\ud83d\udd27 Step 3: Attempting recovery installation...\n\u2705 Step 4: Verifying recovery suite...\n\ud83d\udcdd Step 5: Documenting emergency response...\n\u001b[31mFAILED\u001b[0m\ntests/test_workflows.py::TestComplexIntegrationWorkflows::test_complete_enterprise_deployment_workflow \ud83c\udfe2 Starting Enterprise Deployment Workflow...\n\n\ud83d\udccb Phase 1: Environment Setup\n\n\ud83d\udd0d Phase 2: Server Discovery and Selection\n\n\u2699\ufe0f Phase 3: Environment Configuration\n\n\ud83e\uddea Phase 4: Quality Assurance Testing\n\n\ud83d\udcca Phase 5: Quality Metrics Collection\n\u001b[31mFAILED\u001b[0m\ntests/test_workflows.py::TestComplexIntegrationWorkflows::test_continuous_integration_workflow \ud83d\udd04 Starting Continuous Integration Workflow...\n\n\ud83d\udd27 Phase 1: CI Pipeline Setup\n\n\ud83d\udee0\ufe0f Phase 2: Adding CI Tools\n\n\ud83e\uddea Phase 3: Automated Testing Simulation\n\u001b[31mFAILED\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m______ TestUserOnboardingWorkflows.test_developer_workflow_suite_creation ______\u001b[0m\n\u001b[1m\u001b[31mtests/test_workflows.py\u001b[0m:119: in test_developer_workflow_suite_creation\n    \u001b[0mTestAssertions.assert_command_success(feedback_result, \u001b[33m\"\u001b[39;49;00m\u001b[33mDeveloper: Record feedback\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Developer: Record feedback\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback filesystem dev-test-id --rating 5 --comment Essential for development work\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m_______ TestUserOnboardingWorkflows.test_admin_bulk_management_workflow ________\u001b[0m\n\u001b[1m\u001b[31mtests/test_workflows.py\u001b[0m:171: in test_admin_bulk_management_workflow\n    \u001b[0mTestAssertions.assert_command_success(report_result, \u001b[33m\"\u001b[39;49;00m\u001b[33mAdmin: Quality report\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Admin: Quality report\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality report\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m__________ TestProblemSolvingWorkflows.test_troubleshooting_workflow ___________\u001b[0m\n\u001b[1m\u001b[31mtests/test_workflows.py\u001b[0m:200: in test_troubleshooting_workflow\n    \u001b[0mTestAssertions.assert_contains_all(\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:290: in assert_contains_all\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Problematic server in list\u001b[0m\n\u001b[1m\u001b[31mE   Missing items: ['problematic-server']\u001b[0m\n\u001b[1m\u001b[31mE   In text: \u001b[0m\n\u001b[1m\u001b[31mE                                MCP Servers (47 total)                             \u001b[0m\n\u001b[1m\u001b[31mE   \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\u001b[0m\n\u001b[1m\u001b[31mE   \u2503 Name            \u2503 Type    \u2503 Sc\u2026 \u2503 Sta\u2026 \u2503 Command                             \u2503\u001b[0m\n\u001b[1m\u001b[31mE   \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\n\u001b[31m\u001b[1m______ TestProblemSolvingWorkflows.test_performance_optimization_workflow ______\u001b[0m\n\u001b[1m\u001b[31mtests/test_workflows.py\u001b[0m:269: in test_performance_optimization_workflow\n    \u001b[0mTestAssertions.assert_command_success(feedback_result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mPerformance: Feedback for \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mserver\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Performance: Feedback for http\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback http perf-test --rating 5 --comment Optimized for performance\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m_____________ TestProblemSolvingWorkflows.test_migration_workflow ______________\u001b[0m\n\u001b[1m\u001b[31mtests/test_workflows.py\u001b[0m:334: in test_migration_workflow\n    \u001b[0mTestAssertions.assert_command_success(migration_feedback, \u001b[33m\"\u001b[39;49;00m\u001b[33mMigration: Record feedback\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Migration: Record feedback\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback filesystem migration-test --rating 5 --comment Successful migration to modern config\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m__________ TestCollaborationWorkflows.test_team_development_workflow ___________\u001b[0m\n\u001b[1m\u001b[31mtests/test_workflows.py\u001b[0m:398: in test_team_development_workflow\n    \u001b[0mTestAssertions.assert_command_success(feedback_result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mTeam: Feedback for \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtool\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Team: Feedback for filesystem\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback filesystem team-filesystem --rating 5 --comment Essential for file operations\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m___________ TestCollaborationWorkflows.test_project_handoff_workflow ___________\u001b[0m\n\u001b[1m\u001b[31mtests/test_workflows.py\u001b[0m:433: in test_project_handoff_workflow\n    \u001b[0mTestAssertions.assert_command_success(doc_feedback, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mHandoff: Document \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mserver\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Handoff: Document http\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback http project-alpha --rating 4 --comment Used in Project Alpha - works reliably\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m__________ TestMaintenanceWorkflows.test_routine_maintenance_workflow __________\u001b[0m\n\u001b[1m\u001b[31mtests/test_workflows.py\u001b[0m:489: in test_routine_maintenance_workflow\n    \u001b[0mTestAssertions.assert_command_success(maintenance_report, \u001b[33m\"\u001b[39;49;00m\u001b[33mMaintenance: Generate report\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Maintenance: Generate report\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality report\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m__________ TestMaintenanceWorkflows.test_emergency_recovery_workflow ___________\u001b[0m\n\u001b[1m\u001b[31mtests/test_workflows.py\u001b[0m:541: in test_emergency_recovery_workflow\n    \u001b[0mTestAssertions.assert_command_success(emergency_feedback, \u001b[33m\"\u001b[39;49;00m\u001b[33mEmergency: Document response\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Emergency: Document response\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback filesystem emergency-test --rating 5 --comment Successful emergency recovery\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m_ TestComplexIntegrationWorkflows.test_complete_enterprise_deployment_workflow _\u001b[0m\n\u001b[1m\u001b[31mtests/test_workflows.py\u001b[0m:604: in test_complete_enterprise_deployment_workflow\n    \u001b[0mTestAssertions.assert_command_success(feedback_result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mEnterprise: QA feedback \u001b[39;49;00m\u001b[33m{\u001b[39;49;00menv\u001b[33m}\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mserver\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: Enterprise: QA feedback development filesystem\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback filesystem enterprise-development --rating 4 --comment Enterprise development deployment\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n\u001b[31m\u001b[1m_____ TestComplexIntegrationWorkflows.test_continuous_integration_workflow _____\u001b[0m\n\u001b[1m\u001b[31mtests/test_workflows.py\u001b[0m:660: in test_continuous_integration_workflow\n    \u001b[0mTestAssertions.assert_command_success(feedback_result, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mCI: Record test \u001b[39;49;00m\u001b[33m{\u001b[39;49;00miteration\u001b[90m \u001b[39;49;00m+\u001b[90m \u001b[39;49;00m\u001b[94m1\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m for \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtool\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mtests/utils/validators.py\u001b[0m:217: in assert_command_success\n    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_msg)\u001b[90m\u001b[39;49;00m\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Test: CI: Record test 1 for filesystem\u001b[0m\n\u001b[1m\u001b[31mE   Command: /opt/homebrew/anaconda3/bin/python -m mcp_manager.cli.main quality feedback filesystem ci-iteration-0 --rating 4 --comment CI test iteration 1\u001b[0m\n\u001b[1m\u001b[31mE   Expected: Success\u001b[0m\n\u001b[1m\u001b[31mE   Actual: Failure (code 2)\u001b[0m\n\u001b[1m\u001b[31mE   STDOUT: \u001b[0m\n\u001b[1m\u001b[31mE   STDERR: <frozen runpy>:128: RuntimeWarning: 'mcp_manager.cli.main' found in sys.modules after import of package 'mcp_manager.cli', but prior to execution of 'mcp_manager.cli.main'; this may result in unpredic\u001b[0m\n- generated xml file: /Users/jestes/mcp-manager/tests/results/test-results-user-workflows.xml -\n============================= slowest 10 durations =============================\n5.60s call     tests/test_workflows.py::TestUserOnboardingWorkflows::test_new_user_discovery_to_installation\n4.51s call     tests/test_workflows.py::TestProblemSolvingWorkflows::test_migration_workflow\n3.95s call     tests/test_workflows.py::TestProblemSolvingWorkflows::test_troubleshooting_workflow\n3.38s call     tests/test_workflows.py::TestMaintenanceWorkflows::test_emergency_recovery_workflow\n3.02s call     tests/test_workflows.py::TestMaintenanceWorkflows::test_routine_maintenance_workflow\n2.90s call     tests/test_workflows.py::TestComplexIntegrationWorkflows::test_complete_enterprise_deployment_workflow\n2.69s call     tests/test_workflows.py::TestUserOnboardingWorkflows::test_admin_bulk_management_workflow\n1.59s call     tests/test_workflows.py::TestUserOnboardingWorkflows::test_developer_workflow_suite_creation\n1.04s call     tests/test_workflows.py::TestComplexIntegrationWorkflows::test_continuous_integration_workflow\n0.86s call     tests/test_workflows.py::TestCollaborationWorkflows::test_project_handoff_workflow\n\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n\u001b[31mFAILED\u001b[0m tests/test_workflows.py::\u001b[1mTestUserOnboardingWorkflows::test_developer_workflow_suite_creation\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_workflows.py::\u001b[1mTestUserOnboardingWorkflows::test_admin_bulk_management_workflow\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_workflows.py::\u001b[1mTestProblemSolvingWorkflows::test_troubleshooting_workflow\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_workflows.py::\u001b[1mTestProblemSolvingWorkflows::test_performance_optimization_workflow\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_workflows.py::\u001b[1mTestProblemSolvingWorkflows::test_migration_workflow\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_workflows.py::\u001b[1mTestCollaborationWorkflows::test_team_development_workflow\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_workflows.py::\u001b[1mTestCollaborationWorkflows::test_project_handoff_workflow\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_workflows.py::\u001b[1mTestMaintenanceWorkflows::test_routine_maintenance_workflow\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_workflows.py::\u001b[1mTestMaintenanceWorkflows::test_emergency_recovery_workflow\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_workflows.py::\u001b[1mTestComplexIntegrationWorkflows::test_complete_enterprise_deployment_workflow\u001b[0m - AssertionError: \n\u001b[31mFAILED\u001b[0m tests/test_workflows.py::\u001b[1mTestComplexIntegrationWorkflows::test_continuous_integration_workflow\u001b[0m - AssertionError: \n\u001b[31m======================== \u001b[31m\u001b[1m11 failed\u001b[0m, \u001b[32m1 passed\u001b[0m\u001b[31m in 31.36s\u001b[0m\u001b[31m =========================\u001b[0m\n",
      "stderr": "",
      "command": "python -m pytest tests/test_workflows.py --verbose --tb=short --durations=10 --junitxml=tests/results/test-results-user-workflows.xml --color=yes -s"
    }
  ]
}